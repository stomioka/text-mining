{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling\n",
    "\n",
    "![](images/topic1.png)\n",
    "\n",
    "Some words are highlighted. This demonstrates that any article you see is more likely to be formed of different topics or sub-units that intermingle very seamlessly in weaving out an article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/topic2.png)\n",
    "\n",
    "You have three topics. You have genetics that's in yellow, or computation that's in blue, and life-related, life science, let's say, in pink.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/topic3.png)\n",
    "\n",
    "This shows that documents are typically a mixture of topics. So you have topics coming from genetics, computation, or even anatomy.\n",
    "\n",
    "And each of these topics are basically words that are more probable coming from that topic. When you're talking about genes and DNA and so on, you are mostly in the genetics realm, while if you're talking about brain and neuron and nerve, you are in anatomy. If you're talking about computers and numbers and data and so on, you're most likely in computation. So when a new document comes in, in this case this article on seeking life's bare genetic necessities, it comes with it of topic distribution. And so for that particular article, there is some sort of topic distribution over these topics. Assume there are only four topics in the world. Genetics, computation, life sciences, anatomy. Let's take in this sense that these are the only four topics you have, and this particular article is generated by these four topics in some combination of words. Where anatomy, the green one, is absent, and computation, for example, is the most probable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is topic modeling? (Text Clustering Problem)\n",
    "\n",
    "* **Topic modeling is a coarse-level analysis of what is in a text collection.** When you have a large corpus, and you want to make sense of what this collection is about, you would probably use topic modeling. Because you would say, let's figure out what kind of documents you have in this collection. Are they all about sports? Are they all about business?\n",
    "* **A topic is a subject of theme of a discourse.** And that means that you have some probability of a word appearing in that topic. And different words have different probabilities in that topic. So for example, if you see a basketball, or a player, or a fee, or a score, you are more likely to be in the topic of sports. And if you are in the topic of sports, then words such as player and team and score are more likely to appear. Team may also appear in social science studies but maybe not as frequently, or it's not as probable to have that in, let's say, in life. Though it is likely there as well, right? So for a particular word, you have different distribution or probable occurring from a topic, and topics are basically this probability of distribution over all words. \n",
    "* **Topics are represented by a word distribution**\n",
    "* **A document is assumed to be a mixture of topics.**\n",
    "* What's known:\n",
    "    * The text collection of corpus\n",
    "    * number of topics\n",
    "* What's not known:\n",
    "    * The actual topics\n",
    "    * Topic distribution for each document\n",
    "* Essentially, **text clustering problem*\n",
    "    *Documents and words clustered simultaneously\n",
    "* Different topic modeling approaches available\n",
    "    * Probabilistic Latent Semantic Analysis (PLSA)[Hoffman '99]\n",
    "    * Latent Dirichlet Allocation (LDA) [Blei, Ng, and Jordan, '03] --- one of the most popular modeling approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
