{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Text Similarity\n",
    "## Applications of semantic similarity\n",
    "* Grouping similar words into semantic concepts\n",
    "* As a building block in natural language udnerstnading tasks\n",
    "    * Textual entailment RTEはテキスト間の含意を推論するタスクです。与えられた2つの文章間の関係性を、幾つかの含意を表すラベルで表現します。\n",
    "    * Paraphrasing\n",
    "\n",
    "## WordNet\n",
    "   * WordNet® is a large lexical database of English. Nouns, verbs, adjectives and adverbs are grouped into sets of cognitive synonyms (synsets), each expressing a distinct concept. Synsets are interlinked by means of conceptual-semantic and lexical relations.\n",
    "   * Includes rich linguistic informaiton\n",
    "        * part of speech, word senses, suynonyms, hypernyms/hyponyms, meronyms, derivationally related forms, ...\n",
    "   * Machine readable, freely available\n",
    "   \n",
    "## Semantic similarity using WordNet\n",
    "* WordNet organizes information in a hierachy\n",
    "\n",
    "![](images/semantic1.png)\n",
    "\n",
    "## Path similarity\n",
    "* Find the shrotest path between the two concepts\n",
    "* Similarity measure inversely related to path distance\n",
    "    * PathSim(deer, elk)= 0.5\n",
    "    * PathSim(deer, giraffe)= 0.33\n",
    "\n",
    "## Lowest common subsumer (LCS)\n",
    "* Find the closest ancestor to both concepts\n",
    "\n",
    "\n",
    "![](images/semantic2.png)\n",
    "\n",
    "## Lin Similarity\n",
    "* Similarituy measure based on the information contained in the LCS of the two concepts\n",
    "* $LinSim(u,v) = s * logP\\frac{LCS(u,v)}{logP(u) + log P(v)}$\n",
    "* P(u) is fiven by the inforamtion copntent learnt over a large corpus.\n",
    "\n",
    "## How do you do it in Python?\n",
    "* WordNet easily imported into Python through NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words\n",
    "* Look up a word using synsets(); This function has an optional pos argument which lets you constrain the part of speech of the word:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Find appropriate sense of the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('dog.n.01'),\n",
       " Synset('frump.n.01'),\n",
       " Synset('dog.n.03'),\n",
       " Synset('cad.n.01'),\n",
       " Synset('frank.n.02'),\n",
       " Synset('pawl.n.01'),\n",
       " Synset('andiron.n.01'),\n",
       " Synset('chase.v.01')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " wn.synsets('dog') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds\n"
     ]
    }
   ],
   "source": [
    " print(wn.synset('dog.n.01').definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "deer = wn.synset('deer.n.01') # find me the synset of deer which is a noun and give me the first synset\n",
    "elk = wn.synset('elk.n.01')\n",
    "horse = wn.synset('horse.n.01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Synset: a set of synonyms that share a common meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "上位概念 [Synset('ruminant.n.01')] 下位概念 [Synset('brocket.n.01'), Synset('caribou.n.01'), Synset('elk.n.01'), Synset('fallow_deer.n.01'), Synset('fawn.n.02'), Synset('japanese_deer.n.01'), Synset('mule_deer.n.01'), Synset('muntjac.n.01'), Synset('musk_deer.n.01'), Synset('pere_david's_deer.n.01'), Synset('pricket.n.02'), Synset('red_deer.n.01'), Synset('roe_deer.n.01'), Synset('sambar.n.01'), Synset('virginia_deer.n.01'), Synset('wapiti.n.01')] 特定の単語が全体の一部分となっている名前の単語 [Synset('cervidae.n.01')]\n"
     ]
    }
   ],
   "source": [
    "print('上位概念', deer.hypernyms(), '下位概念', deer.hyponyms(), '特定の単語が全体の一部分となっている名前の単語', deer.member_holonyms())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Find path similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deer.path_similarity(elk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14285714285714285"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deer.path_similarity(horse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use an information criteria to find LinSimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet_ic to\n",
      "[nltk_data]     C:\\Users\\Sam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet_ic.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download('wordnet_ic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8623778273893673 0.7726998936065773\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet_ic\n",
    "brown_ic = wordnet_ic.ic('ic-brown.dat')\n",
    "print(deer.lin_similarity(elk,brown_ic),\n",
    "deer.lin_similarity(horse,brown_ic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collocations and Distributional similarity\n",
    "* \"You know a word by the company it keeps\" [Firth, 1957]\n",
    "* Two words that frequently appears in similar context are more likely to be semantically related\n",
    "\n",
    "![](images/semantic3.png)\n",
    "\n",
    "* Words before, after, within a small window\n",
    "* Parts of speech of words before, after, in a small window\n",
    "* Specific syntactic relation to the traget word\n",
    "* Words in the same sentence, same document, ...\n",
    "\n",
    "## Strength of association between words\n",
    "* How frequent are these?\n",
    "    * Not similar if two words don't occur together often\n",
    "    * Also important to see how frequent are individual words\n",
    "        * 'the' is very frequent, so high chances it co-occurs often with every other word\n",
    "    * Pointwise Mutual Information $PMI(w,c)= log\\frac{P(w,c)}{P(w)P(c)}$\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.collocations import *\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "finder=BigramCollocationFinder.from_words(text)\n",
    "finder.nbest(bigram_measures.pmi,10) # get top 10 measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* finder also has other useful functions such as frequency filter\n",
    "\n",
    "`finder.apply_freq_filter(10)`\n",
    "\n",
    "suppose you want all bigram measures that are, there you have supposed 10 or more occurrences of words only then can you keep them, then you could do something like finder.apply_ freq_filter (10). That would then restrict any pair that does not occur at least 10 times in your corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
